{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2fa910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON block:\n",
      " {\"id\": 34, \"question\": \"Create the histogram for the runners of the \\\"10 Mile\"\\ event. Describe the overall shape of the histogram.What does this suggest about the structure of the age distribution of the runners?Calculate some simple summary statistics to support your comments.\",\"concepts\": [\"Data Visualization-Summary\"],\"format\": \"@histogram_10mile_summary_stats[histogram_10mile_summary_stats] where \\\"histogram_10mile_summary_stats\\\" is the created histogram and additional summary statistics\",\"file_name\": \"cherryblossom_run17.xlsx\", \"level\": \"medium\"}\n",
      "Invalid JSON block:\n",
      " {\"id\": 34.1, \"question\": \"Create a similar data visualisation for the \\\"5K\"\\ race event.Describe the shape of this histogram and discuss the similarities/differences of the age distribution between the \\\"5K\"\\ and \\\"10 Mile\"\\ races.\",\"concepts\": [\"Data Visualization-Interpretation\"],\"format\": \"@histogram_10mile_5mile_comparison[histogram_10mile_5mile_comparison] where \\\"histogram_10mile_5mile_comparison\\\" is the created histogram and additional comparison comments\",\"file_name\": \"cherryblossom_run17.xlsx\", \"level\": \"hard\"}\n",
      "Invalid JSON block:\n",
      " {\"id\": 37, \"question\": \"Create a new data frame called gss16_advfront that includes the variables advfront, emailhr (Number of hours spent on email weekly),educ (education level), polviews (political views) and wrkstat (working status). Remove any row that contains any NAs.Relevel the advfront variable based on \\\"Agree\"\\ - combining the options \\\"Strongly agree\"\\ and \\\"Agree\"\\ and \\\"Not agree\"\\ - combining the options \\\"Dont know\"\\, \\\"Disagree\"\\ and \\\"Strongly disagree\"\\.Besides, relevel the polviews to simplify the range of options to 3 categories - \\\"Conservative\"\\, \\\"Moderate\"\\, and \\\"Liberal\"\\.Creating a new fulltime variable that is equal to TRUE if wrkstat is equal to \\\"Working fulltime\"\\ and FALSE otherwise.Save the name data set as a new data frame called 'gss16_advfront'\",\"concepts\": [\"Data Cleaning-Preparation\"],\"format\": \"@gss16_data_set_cleaning[gss16_data_set_cleaning] where \\\"gss16_data_set_cleaning\\\" is the cleaned data set based on given data and instructions\",\"file_name\": \"gss16.csv\", \"level\": \"hard\"}\n",
      "Invalid JSON block:\n",
      " {\"id\": 41, \"question\": \"In the context of an email spam detection system, describe the terms \\\"True Positive\"\\, \\\"False Positive\"\\, \\\"True Negative\"\\, and \\\"False Negative\"\\ \",\"concepts\": [\"Specific Descriptions\"],\"format\": \"@Confusion_definitions[Confusion_definitions] where \\\"Confusion_definitions\\\" is the verbal definitions for the given quantities.\",\"file_name\": \"\", \"level\": \"easy\"}\n",
      "Invalid JSON block:\n",
      " {\"id\": 45, \"question\": \"For the given data frames in tibble format,```df1 <- tibble(x = 1:3)df2 <- tibble(x = c(1, 1, 2), y = c(\"first\", \"second\", \"third\"))```Apply the joining procedure results in a new data frame with missing value.\",\"concepts\": [\"Data Preparation\"],\"format\": \"@df1_df2_merged[df1_df2_merged] where \\\"df1_df2_merged\\\" is the merged data frame based on given condition\",\"file_name\": \"\", \"level\": \"easy\"}\n",
      "Parsed 101 JSON objects\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re \n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "buffer = \"\"\n",
    "invalid_blocks = []\n",
    "\n",
    "\n",
    "def fix_inner_quotes(line: str) -> str:\n",
    "    # Find the pattern: text inside double quotes within a JSON string\n",
    "    # Example: 'dfasf \"sth\" dfads' → replace inner quotes with escaped\n",
    "    pattern = r'(\"question\":\\s*\")(.*?)(?<!\\\\)\"(.*?)(?<!\\\\)\"(.*?)(\")'\n",
    "    fixed_line = re.sub(pattern, r'\\1\\2\\\"\\3\\\"\\4\\5', line)\n",
    "    return fixed_line\n",
    "\n",
    "\n",
    "with open('GAIL-DA-tasks-questions.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Skip comment lines\n",
    "        if line.startswith(\"##\") or line.startswith('%'):\n",
    "            continue\n",
    "        \n",
    "        # If line is empty and we have a JSON block collected\n",
    "        if not line and buffer:\n",
    "            try:\n",
    "                obj = json.loads(buffer)\n",
    "                data.append(obj)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"Invalid JSON block:\\n\", buffer)\n",
    "                invalid_blocks.append(buffer)\n",
    "                # print(\"Error:\", e)\n",
    "\n",
    "            buffer = \"\"\n",
    "        else:\n",
    "            buffer += line  # accumulate multi-line JSON objects\n",
    "\n",
    "data.append({\"id\": 34, \"question\": \"Create the histogram for the runners of the \\\"10 Mile\\\" event. Describe the overall shape of the histogram.What does this suggest about the structure of the age distribution of the runners?Calculate some simple summary statistics to support your comments.\",\"concepts\": [\"Data Visualization-Summary\"],\"constraints\": \"Calculate the summary statistics and histogram using R's tidyverse functionalities\",\"format\": \"@histogram_10mile_summary_stats[histogram_10mile_summary_stats] where \\\"histogram_10mile_summary_stats\\\" is the created histogram and additional summary statistics\",\"file_name\": \"cherryblossom::run17\", \"level\": \"medium\"})\n",
    "data.append({\"id\": 34.1, \"question\": \"Create a similar data visualisation for the \\\"5K\\\" race event.Describe the shape of this histogram and discuss the similarities/differences of the age distribution between the \\\"5K\\\" and \\\"10 Mile\\\"races.\",\"concepts\": [\"Data Visualization-Interpretation\"],\"constraints\": \"Create the histogram and related comparison using R's tidyverse functionalities\",\"format\": \"@histogram_10mile_5mile_comparison[histogram_10mile_5mile_comparison] where \\\"histogram_10mile_5mile_comparison\\\" is the created histogram and additional comparison comments\",\"file_name\": \"cherryblossom::run17\", \"level\": \"hard\"})\n",
    "data.append({\"id\": 37, \"question\": \"Create a new data frame called gss16_advfront that includes the variables advfront, emailhr (Number of hours spent on email weekly),educ (education level), polviews (political views) and wrkstat (working status). Remove any row that contains any NAs.Relevel the advfront variable based on \\\"Agree\\\" - combining the options \\\"Strongly agree\\\" and \\\"Agree\\\" and \\\"Not agree\\\" - combining the options \\\"Dont know\\\", \\\"Disagree\\\" and \\\"Strongly disagree\\\".Besides, relevel the polviews to simplify the range of options to 3 categories - \\\"Conservative\\\" , \\\"Moderate\\\", and \\\"Liberal\\\".Creating a new fulltime variable that is equal to TRUE if wrkstat is equal to \\“Working fulltime\\” and FALSE otherwise.Save the name data set as a new data frame called 'gss16_advfront'\",\"concepts\": [\"Data Cleaning-Preparation\"],\"constraints\": \"Cleaning the data set using R's tidyverse functionalities\",\"format\": \"@gss16_data_set_cleaning[gss16_data_set_cleaning] where \\\"gss16_data_set_cleaning\\\" is the cleaned data set based on given data and instructions\",\"file_name\": \"gss16.csv\", \"level\": \"hard\"})\n",
    "data.append({\"id\": 45, \"question\": \"For the given data frames in tibble format,```df1 <- tibble(x = 1:3)df2 <- tibble(x = c(1, 1, 2), y = c(\\\"first\\\", \\\"second\\\", \\\"third\\\"))```Apply the joining procedure results in a new data frame with missing value.\",\"concepts\": [\"Data Preparation\"],\"constraints\": \"Merging the given specific dfs using R's tidyverse functionalities\",\"format\": \"@df1_df2_merged[df1_df2_merged] where \\\"df1_df2_merged\\\" is the merged data frame based on given condition\",\"file_name\": \"\", \"level\": \"easy\"})\n",
    "data.append({\"id\": 41, \"question\": \"In the context of an email spam detection system, describe the terms \\\"True Positive\\\"\\, \\\"False Positive\\\"\\, \\\"True Negative\\\"\\, and \\\"False Negative\\\"\\ \",\"concepts\": [\"Specific Descriptions\"],\"constraints\": \"Giving the descriptions of the mentioned quantities\",\"format\": \"@Confusion_definitions[Confusion_definitions] where \\\"Confusion_definitions\\\" is the verbal definitions for the given quantities.\",\"file_name\": \"\", \"level\": \"easy\"})\n",
    "\n",
    "print(f\"Parsed {len(data)} JSON objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b09840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num = len(data)\n",
    "ids = [data[i]['id'] for i in range(num)]\n",
    "levels = [data[i]['level'] for i in range(num)]\n",
    "filenames = [data[i]['file_name'] for i in range(num)]\n",
    "concepts = [data[i]['concepts'][0] for i in range(num)]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "levels_counter = Counter(levels)\n",
    "filenames_counter = Counter(filenames)\n",
    "concepts_counter = Counter(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3872a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_concept = sum(concepts_counter.values())\n",
    "ratio_concept = {key: (value, value / total_concept) for key, value in concepts_counter.items()}\n",
    "\n",
    "total_level = sum(levels_counter.values())\n",
    "ratio_level = {key: (value, value / total_level) for key, value in levels_counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc99e456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'easy': (22, 0.21782178217821782),\n",
       " 'medium': (40, 0.39603960396039606),\n",
       " 'hard': (39, 0.38613861386138615)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953a1bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>filename</th>\n",
       "      <th>concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>UK-visitor-numbers.csv</td>\n",
       "      <td>Data understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>UK-visitor-numbers.csv</td>\n",
       "      <td>Data understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>UK-visitor-numbers.csv</td>\n",
       "      <td>Data understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>UK-visitor-numbers.csv</td>\n",
       "      <td>Data understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>UK-visitor-numbers.csv</td>\n",
       "      <td>Data understanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>34.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>cherryblossom::run17</td>\n",
       "      <td>Data Visualization-Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>34.1</td>\n",
       "      <td>hard</td>\n",
       "      <td>cherryblossom::run17</td>\n",
       "      <td>Data Visualization-Interpretation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>37.0</td>\n",
       "      <td>hard</td>\n",
       "      <td>gss16.csv</td>\n",
       "      <td>Data Cleaning-Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>45.0</td>\n",
       "      <td>easy</td>\n",
       "      <td></td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>41.0</td>\n",
       "      <td>easy</td>\n",
       "      <td></td>\n",
       "      <td>Specific Descriptions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   level                filename                            concept\n",
       "0     0.0    easy  UK-visitor-numbers.csv                 Data understanding\n",
       "1     1.0    easy  UK-visitor-numbers.csv                 Data understanding\n",
       "2     2.0    easy  UK-visitor-numbers.csv                 Data understanding\n",
       "3     3.0    easy  UK-visitor-numbers.csv                 Data understanding\n",
       "4     4.0  medium  UK-visitor-numbers.csv                 Data understanding\n",
       "..    ...     ...                     ...                                ...\n",
       "96   34.0  medium    cherryblossom::run17         Data Visualization-Summary\n",
       "97   34.1    hard    cherryblossom::run17  Data Visualization-Interpretation\n",
       "98   37.0    hard               gss16.csv          Data Cleaning-Preparation\n",
       "99   45.0    easy                                           Data Preparation\n",
       "100  41.0    easy                                      Specific Descriptions\n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_data = {'id':ids, 'level':levels, 'filename':filenames, 'concept':concepts}\n",
    "df = pd.DataFrame(data=key_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ffff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for filename in set(filenames):\n",
    "    df_file = df[df['filename'] == filename]\n",
    "\n",
    "\n",
    "\n",
    "    summary.append([filename,\n",
    "                    set(df_file['id']),\n",
    "                    Counter(df_file['level']),\n",
    "                    Counter(df_file['concept'])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9518e97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>questions</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>concepts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>{40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 52.0, 55.0}</td>\n",
       "      <td>{'easy': 6, 'medium': 2}</td>\n",
       "      <td>{'CI Interpretation': 1, 'Summary Statistics':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ggplot::diamonds</td>\n",
       "      <td>{15.1, 16.0, 16.1, 17.0, 15.0, 18.0, 19.0, 20.0}</td>\n",
       "      <td>{'hard': 4, 'medium': 4}</td>\n",
       "      <td>{'General EDA': 1, 'Data cleaning': 1, 'Data t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edinburgh_rainfall.csv</td>\n",
       "      <td>{71.2, 71.4, 71.3, 71.1, 71.0, 72.0}</td>\n",
       "      <td>{'hard': 4, 'medium': 2}</td>\n",
       "      <td>{'Bayesian Regression Model': 4, 'Bayesian Reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gss16_advfront.csv</td>\n",
       "      <td>{38.1, 39.1, 38.0, 39.0}</td>\n",
       "      <td>{'medium': 1, 'hard': 3}</td>\n",
       "      <td>{'Regression Modeling': 2, 'Logistic Regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gene_Data.RData / Gene_Data.xlsx</td>\n",
       "      <td>{66.0, 67.0, 68.0, 69.0}</td>\n",
       "      <td>{'medium': 2, 'hard': 2}</td>\n",
       "      <td>{'Data Description': 1, 'PCA': 1, 'Clustering'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>edibnb.csv, council_assessments.csv</td>\n",
       "      <td>{33.0}</td>\n",
       "      <td>{'hard': 1}</td>\n",
       "      <td>{'Data Summary': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cherryblossom_run17.xlsx</td>\n",
       "      <td>{35.0, 36.0}</td>\n",
       "      <td>{'hard': 2}</td>\n",
       "      <td>{'Data Visualization': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mouse.txt</td>\n",
       "      <td>{53.0, 54.0}</td>\n",
       "      <td>{'medium': 1, 'easy': 1}</td>\n",
       "      <td>{'Data Visualization': 1, 'Data Summary': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>laptop_data_cleaned.csv</td>\n",
       "      <td>{73.0, 46.0, 47.1, 48.0, 48.1, 47.0, 49.0, 50....</td>\n",
       "      <td>{'easy': 1, 'medium': 4, 'hard': 4}</td>\n",
       "      <td>{'Data Summary': 1, 'Data Visualization': 2, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stats_diamonds.xlsx</td>\n",
       "      <td>{70.1, 70.3, 70.2, 70.0}</td>\n",
       "      <td>{'easy': 2, 'medium': 1, 'hard': 1}</td>\n",
       "      <td>{'Linear Regression': 1, 'Regression Model Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>instructional-staff.csv</td>\n",
       "      <td>{14.2, 14.0, 14.1}</td>\n",
       "      <td>{'easy': 1, 'medium': 2}</td>\n",
       "      <td>{'Data visualization': 2, 'Data visualization-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>weatherAUS.csv</td>\n",
       "      <td>{74.0, 75.0, 30.2, 30.1, 27.0, 28.0, 29.0, 30.0}</td>\n",
       "      <td>{'easy': 1, 'medium': 4, 'hard': 3}</td>\n",
       "      <td>{'Data Transformation': 1, 'Logistic Regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aeroplane.txt</td>\n",
       "      <td>{56.0, 57.0, 58.0}</td>\n",
       "      <td>{'medium': 2, 'hard': 1}</td>\n",
       "      <td>{'Hypothesis Testing': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>edibnb.csv</td>\n",
       "      <td>{32.0, 31.0}</td>\n",
       "      <td>{'easy': 2}</td>\n",
       "      <td>{'Data Understanding': 1, 'Data Summary': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>evals.csv</td>\n",
       "      <td>{26.1, 23.1, 21.0, 22.0, 23.2, 23.0, 24.0, 26....</td>\n",
       "      <td>{'medium': 6, 'hard': 3}</td>\n",
       "      <td>{'Data Viz and EDA': 2, 'Regression Modeling':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>joined_plastic_data_all.csv</td>\n",
       "      <td>{10.0, 11.0, 12.0, 13.0}</td>\n",
       "      <td>{'easy': 2, 'medium': 2}</td>\n",
       "      <td>{'Data summary': 1, 'Data Understanding': 1, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cherryblossom::run17</td>\n",
       "      <td>{34.0, 34.1}</td>\n",
       "      <td>{'medium': 1, 'hard': 1}</td>\n",
       "      <td>{'Data Visualization-Summary': 1, 'Data Visual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gss16.csv</td>\n",
       "      <td>{37.0}</td>\n",
       "      <td>{'hard': 1}</td>\n",
       "      <td>{'Data Cleaning-Preparation': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>duke_forest.xlsx</td>\n",
       "      <td>{64.0, 65.0, 65.1, 65.2, 61.0, 61.2, 59.0, 60....</td>\n",
       "      <td>{'easy': 2, 'medium': 2, 'hard': 7}</td>\n",
       "      <td>{'Data Visualization': 1, 'Confidence Interval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UK-visitor-numbers.csv</td>\n",
       "      <td>{0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>{'easy': 4, 'medium': 4, 'hard': 2}</td>\n",
       "      <td>{'Data understanding': 5, 'Data summary': 2, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                dataset  \\\n",
       "0                                         \n",
       "1                      ggplot::diamonds   \n",
       "2                Edinburgh_rainfall.csv   \n",
       "3                    gss16_advfront.csv   \n",
       "4      Gene_Data.RData / Gene_Data.xlsx   \n",
       "5   edibnb.csv, council_assessments.csv   \n",
       "6              cherryblossom_run17.xlsx   \n",
       "7                             mouse.txt   \n",
       "8               laptop_data_cleaned.csv   \n",
       "9                   Stats_diamonds.xlsx   \n",
       "10              instructional-staff.csv   \n",
       "11                       weatherAUS.csv   \n",
       "12                        aeroplane.txt   \n",
       "13                           edibnb.csv   \n",
       "14                            evals.csv   \n",
       "15          joined_plastic_data_all.csv   \n",
       "16                 cherryblossom::run17   \n",
       "17                            gss16.csv   \n",
       "18                     duke_forest.xlsx   \n",
       "19               UK-visitor-numbers.csv   \n",
       "\n",
       "                                            questions  \\\n",
       "0    {40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 52.0, 55.0}   \n",
       "1    {15.1, 16.0, 16.1, 17.0, 15.0, 18.0, 19.0, 20.0}   \n",
       "2                {71.2, 71.4, 71.3, 71.1, 71.0, 72.0}   \n",
       "3                            {38.1, 39.1, 38.0, 39.0}   \n",
       "4                            {66.0, 67.0, 68.0, 69.0}   \n",
       "5                                              {33.0}   \n",
       "6                                        {35.0, 36.0}   \n",
       "7                                        {53.0, 54.0}   \n",
       "8   {73.0, 46.0, 47.1, 48.0, 48.1, 47.0, 49.0, 50....   \n",
       "9                            {70.1, 70.3, 70.2, 70.0}   \n",
       "10                                 {14.2, 14.0, 14.1}   \n",
       "11   {74.0, 75.0, 30.2, 30.1, 27.0, 28.0, 29.0, 30.0}   \n",
       "12                                 {56.0, 57.0, 58.0}   \n",
       "13                                       {32.0, 31.0}   \n",
       "14  {26.1, 23.1, 21.0, 22.0, 23.2, 23.0, 24.0, 26....   \n",
       "15                           {10.0, 11.0, 12.0, 13.0}   \n",
       "16                                       {34.0, 34.1}   \n",
       "17                                             {37.0}   \n",
       "18  {64.0, 65.0, 65.1, 65.2, 61.0, 61.2, 59.0, 60....   \n",
       "19  {0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                             difficulty  \\\n",
       "0              {'easy': 6, 'medium': 2}   \n",
       "1              {'hard': 4, 'medium': 4}   \n",
       "2              {'hard': 4, 'medium': 2}   \n",
       "3              {'medium': 1, 'hard': 3}   \n",
       "4              {'medium': 2, 'hard': 2}   \n",
       "5                           {'hard': 1}   \n",
       "6                           {'hard': 2}   \n",
       "7              {'medium': 1, 'easy': 1}   \n",
       "8   {'easy': 1, 'medium': 4, 'hard': 4}   \n",
       "9   {'easy': 2, 'medium': 1, 'hard': 1}   \n",
       "10             {'easy': 1, 'medium': 2}   \n",
       "11  {'easy': 1, 'medium': 4, 'hard': 3}   \n",
       "12             {'medium': 2, 'hard': 1}   \n",
       "13                          {'easy': 2}   \n",
       "14             {'medium': 6, 'hard': 3}   \n",
       "15             {'easy': 2, 'medium': 2}   \n",
       "16             {'medium': 1, 'hard': 1}   \n",
       "17                          {'hard': 1}   \n",
       "18  {'easy': 2, 'medium': 2, 'hard': 7}   \n",
       "19  {'easy': 4, 'medium': 4, 'hard': 2}   \n",
       "\n",
       "                                             concepts  \n",
       "0   {'CI Interpretation': 1, 'Summary Statistics':...  \n",
       "1   {'General EDA': 1, 'Data cleaning': 1, 'Data t...  \n",
       "2   {'Bayesian Regression Model': 4, 'Bayesian Reg...  \n",
       "3   {'Regression Modeling': 2, 'Logistic Regressio...  \n",
       "4   {'Data Description': 1, 'PCA': 1, 'Clustering'...  \n",
       "5                                 {'Data Summary': 1}  \n",
       "6                           {'Data Visualization': 2}  \n",
       "7        {'Data Visualization': 1, 'Data Summary': 1}  \n",
       "8   {'Data Summary': 1, 'Data Visualization': 2, '...  \n",
       "9   {'Linear Regression': 1, 'Regression Model Dia...  \n",
       "10  {'Data visualization': 2, 'Data visualization-...  \n",
       "11  {'Data Transformation': 1, 'Logistic Regressio...  \n",
       "12                          {'Hypothesis Testing': 3}  \n",
       "13       {'Data Understanding': 1, 'Data Summary': 1}  \n",
       "14  {'Data Viz and EDA': 2, 'Regression Modeling':...  \n",
       "15  {'Data summary': 1, 'Data Understanding': 1, '...  \n",
       "16  {'Data Visualization-Summary': 1, 'Data Visual...  \n",
       "17                   {'Data Cleaning-Preparation': 1}  \n",
       "18  {'Data Visualization': 1, 'Confidence Interval...  \n",
       "19  {'Data understanding': 5, 'Data summary': 2, '...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.DataFrame(summary,columns=['dataset','questions','difficulty','concepts'])\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39200574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21.0, 22.0, 23.0, 23.1, 23.2, 24.0, 25.0, 26.0, 26.1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.iloc[14,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddceca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1042ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>8</td>\n",
       "      <td>7.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Regression Modeling</td>\n",
       "      <td>6</td>\n",
       "      <td>5.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Summary</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Understanding</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data understanding</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data summary</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bayesian Regression Model</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hypothesis Testing</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Regression Modeling Interpretation</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data visualization</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data transformation-summary</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Function Writing - Data Summary</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Regression Model Diagnostics</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PCA</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Confidence Interval</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Viz and EDA</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Clustering</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Descriptive Statistics</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data visualization-customization</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Confusion Matrix details</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Logistic Regression Model Performance</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Transformation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Regression Modeling interpretations</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Model Diagnostic Visualization</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data description</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>General EDA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data summary-interpretation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Data cleaning</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data transformation - Data summary</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Action Suggestion</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Interpretation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Modeling Comparison</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Logistic Regression Modeling</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Model Performance-Visualization</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CI Interpretation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ridge-Lasso Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bootstrap CI</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Classification Model</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Model Improvement</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Summary Statistics</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Regression Model</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Regression Coefficient Testing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Data Description</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Regression Model diagnostics</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bayesian Regression Model Checks</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Data Interpretation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Data Visualization-Summary</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Data Visualization-Interpretation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Data Cleaning-Preparation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Specific Descriptions</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Statistic  Count Percentage\n",
       "0                      Data Visualization      8       7.9%\n",
       "1                     Regression Modeling      6       5.9%\n",
       "2                            Data Summary      5       5.0%\n",
       "3                      Data Understanding      5       5.0%\n",
       "4                      Data understanding      5       5.0%\n",
       "5                            Data summary      4       4.0%\n",
       "6               Bayesian Regression Model      4       4.0%\n",
       "7                       Linear Regression      3       3.0%\n",
       "8                      Hypothesis Testing      3       3.0%\n",
       "9               Logistic Regression Model      3       3.0%\n",
       "10     Regression Modeling Interpretation      2       2.0%\n",
       "11                     Data visualization      2       2.0%\n",
       "12            Data transformation-summary      2       2.0%\n",
       "13        Function Writing - Data Summary      2       2.0%\n",
       "14           Regression Model Diagnostics      2       2.0%\n",
       "15                                    PCA      2       2.0%\n",
       "16           Linear Discriminant Analysis      2       2.0%\n",
       "17                    Confidence Interval      2       2.0%\n",
       "18                       Data Viz and EDA      2       2.0%\n",
       "19                             Clustering      2       2.0%\n",
       "20                 Descriptive Statistics      2       2.0%\n",
       "21       Data visualization-customization      1       1.0%\n",
       "22               Confusion Matrix details      1       1.0%\n",
       "23  Logistic Regression Model Performance      1       1.0%\n",
       "24                    Data Transformation      1       1.0%\n",
       "25    Regression Modeling interpretations      1       1.0%\n",
       "26         Model Diagnostic Visualization      1       1.0%\n",
       "27                       Data description      1       1.0%\n",
       "28                            General EDA      1       1.0%\n",
       "29            Data summary-interpretation      1       1.0%\n",
       "30                          Data cleaning      1       1.0%\n",
       "31     Data transformation - Data summary      1       1.0%\n",
       "32                      Action Suggestion      1       1.0%\n",
       "33                         Interpretation      1       1.0%\n",
       "34                    Modeling Comparison      1       1.0%\n",
       "35           Logistic Regression Modeling      1       1.0%\n",
       "36        Model Performance-Visualization      1       1.0%\n",
       "37                      CI Interpretation      1       1.0%\n",
       "38                 Ridge-Lasso Regression      1       1.0%\n",
       "39                           Bootstrap CI      1       1.0%\n",
       "40                   Classification Model      1       1.0%\n",
       "41                      Model Improvement      1       1.0%\n",
       "42                     Summary Statistics      1       1.0%\n",
       "43                       Regression Model      1       1.0%\n",
       "44         Regression Coefficient Testing      1       1.0%\n",
       "45                       Data Description      1       1.0%\n",
       "46           Regression Model diagnostics      1       1.0%\n",
       "47       Bayesian Regression Model Checks      1       1.0%\n",
       "48                    Data Interpretation      1       1.0%\n",
       "49             Data Visualization-Summary      1       1.0%\n",
       "50      Data Visualization-Interpretation      1       1.0%\n",
       "51              Data Cleaning-Preparation      1       1.0%\n",
       "52                       Data Preparation      1       1.0%\n",
       "53                  Specific Descriptions      1       1.0%"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = pd.DataFrame([\n",
    "    [f\"{k}\", v[0], f\"{v[1]*100:.1f}%\"] for k, v in ratio_concept.items()\n",
    "], columns=[\"Statistic\", \"Count\", \"Percentage\"])\n",
    "\n",
    "df_cat=df_cat.sort_values(by='Count',ascending=False).reset_index(drop=True)\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755cd05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total tasks</td>\n",
       "      <td>101</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>easy</td>\n",
       "      <td>22</td>\n",
       "      <td>21.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>40</td>\n",
       "      <td>39.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard</td>\n",
       "      <td>39</td>\n",
       "      <td>38.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Statistic  Count Percentage\n",
       "0  Total tasks    101       100%\n",
       "1         easy     22      21.8%\n",
       "2       medium     40      39.6%\n",
       "3         hard     39      38.6%"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = pd.DataFrame([[\"Total tasks\", num, \"100%\"]], columns=df_cat.columns)\n",
    "df_diff = pd.DataFrame([\n",
    "    [f\"{k}\", v[0], f\"{v[1]*100:.1f}%\"] for k, v in ratio_level.items()\n",
    "], columns=[\"Statistic\", \"Count\", \"Percentage\"])\n",
    "\n",
    "pd.concat([df_total, df_diff], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f366c367",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m n = \u001b[32m10\u001b[39m \u001b[38;5;66;03m# number of top features\u001b[39;00m\n\u001b[32m      4\u001b[39m df_sorted = df_cat\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10 # number of top features\n",
    "\n",
    "df_sorted = df_cat\n",
    "\n",
    "top_df = df_sorted.iloc[:n].copy()\n",
    "top_df[\"Label\"] = top_df[\"Statistic\"]\n",
    "\n",
    "# Group the rest as 'Others'\n",
    "other_count = df_sorted.iloc[n:][\"Count\"].sum()\n",
    "other_ratio = df_sorted.iloc[n:][\"Percentage\"].sum()\n",
    "others = pd.DataFrame([{\n",
    "    \"Statistic\": \"Others\",\n",
    "    \"Count\": other_count,\n",
    "    \"Percentage\": other_ratio,\n",
    "    \"Label\": \"Others\"\n",
    "}])\n",
    "\n",
    "# Combine top n + others\n",
    "pie_df = pd.concat([top_df, others], ignore_index=True)\n",
    "\n",
    "# Custom colors: unique for top n + one for Others\n",
    "# colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d3d3d3\"]  # last one is light gray for \"Others\"\n",
    "\n",
    "# Pie chart\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(\n",
    "    pie_df[\"Count\"],\n",
    "    labels=pie_df[\"Label\"],\n",
    "    # colors=colors,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140\n",
    ")\n",
    "plt.title(f\"Top {n} Categories + Others\")\n",
    "plt.axis(\"equal\")  # Equal aspect ratio\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1279c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel('cherryblossom_run17.xlsx')\n",
    "# Save it as a CSV file\n",
    "df.to_csv('cherryblossom_run17.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3ba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
